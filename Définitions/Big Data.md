Le **Big Data** est un terme employé depuis les années 1990 pour désigner un ensemble de données non structurées, semi-structurées et structurées au volume important.

Le concept de Big Data a pris de l'ampleur au début des années 2000, lorsque l'analyste industriel Doug Laney a défini ses caractéristiques en trois "V" :

**Volume :** des données massives issues de multiples sources (réseaux sociaux, IoT, etc.) stockées sur des plateformes dédiées (Data lakes, Hadoop). Le volume peut varier de dizaines de téraoctets à des centaines de pétaoctets selon les entreprises.

**Vitesse :** des données générées et traitées en temps quasi réel, surtout pour les produits intelligents liés à l'IoT. La production est plus continue que pour les données à faible volume.

**Variété :** des données structurées et non structurées (texte, audio, vidéo) qui nécessitent un prétraitement pour en extraire le sens et gérer les métadonnées.

---
Source : [Oracle. What is Big Data?](https://www.oracle.com/a/ocom/docs/what-is-big-data-ebook-4421383.pdf)